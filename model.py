"""
Glioma Tumor Detection System using EVGG-CNN Architecture
A Deep Learning Based Approach with Modified Firefly Optimizer
"""

import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from sklearn.model_selection import train_test_split
import cv2
import os
from skimage.feature import graycomatrix, graycoprops
from scipy.spatial import distance
import pickle

# ============================================================================
# 1. EFFICIENT VGG-CNN ARCHITECTURE
# ============================================================================

class EVGG_CNN:
    """Efficient VGG-CNN Architecture for Glioma Detection"""
    
    def __init__(self, input_shape=(224, 224, 3), num_classes=2):
        self.input_shape = input_shape
        self.num_classes = num_classes
        self.model = None
        
    def build_model(self):
        """Build the Efficient VGG-CNN architecture"""
        
        model = models.Sequential([
            # Block 1
            layers.Conv2D(64, (3, 3), activation='relu', padding='same', 
                         input_shape=self.input_shape, name='block1_conv1'),
            layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2'),
            layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'),
            layers.BatchNormalization(),
            
            # Block 2
            layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1'),
            layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2'),
            layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool'),
            layers.BatchNormalization(),
            
            # Block 3
            layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1'),
            layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2'),
            layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3'),
            layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool'),
            layers.BatchNormalization(),
            
            # Block 4
            layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1'),
            layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2'),
            layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3'),
            layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool'),
            layers.BatchNormalization(),
            
            # Fully Connected Layers
            layers.Flatten(),
            layers.Dense(4096, activation='relu', name='fc1'),
            layers.Dropout(0.5),
            layers.Dense(4096, activation='relu', name='fc2'),
            layers.Dropout(0.5),
            layers.Dense(self.num_classes, activation='softmax', name='predictions')
        ])
        
        self.model = model
        return model
    
    def compile_model(self, learning_rate=0.0001):
        """Compile the model with optimizer and loss"""
        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)
        self.model.compile(
            optimizer=optimizer,
            loss='categorical_crossentropy',
            metrics=['accuracy', 'precision', 'recall']
        )
        
    def train(self, X_train, y_train, X_val, y_val, epochs=100, batch_size=32):
        """Train the model"""
        
        # Data augmentation
        datagen = ImageDataGenerator(
            rotation_range=20,
            width_shift_range=0.2,
            height_shift_range=0.2,
            horizontal_flip=True,
            zoom_range=0.2,
            fill_mode='nearest'
        )
        
        # Callbacks
        callbacks = [
            keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),
            keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5),
            keras.callbacks.ModelCheckpoint('best_evgg_model.h5', save_best_only=True)
        ]
        
        # Train
        history = self.model.fit(
            datagen.flow(X_train, y_train, batch_size=batch_size),
            validation_data=(X_val, y_val),
            epochs=epochs,
            callbacks=callbacks,
            verbose=1
        )
        
        return history


# ============================================================================
# 2. MODIFIED FIREFLY OPTIMIZER FOR SEGMENTATION
# ============================================================================

class ModifiedFireflyOptimizer:
    """Modified Firefly Algorithm for Tumor Segmentation"""
    
    def __init__(self, n_fireflies=20, max_iterations=100, alpha=0.5, beta=1.0, gamma=1.0):
        self.n_fireflies = n_fireflies
        self.max_iterations = max_iterations
        self.alpha = alpha  # Randomization parameter
        self.beta = beta    # Attraction coefficient
        self.gamma = gamma  # Light absorption coefficient
        
    def objective_function(self, threshold, image):
        """Calculate segmentation quality using Otsu's method"""
        _, binary = cv2.threshold(image, int(threshold), 255, cv2.THRESH_BINARY)
        
        # Calculate between-class variance
        hist = cv2.calcHist([image], [0], None, [256], [0, 256])
        hist = hist.ravel() / hist.sum()
        
        bins = np.arange(256)
        
        # Class probabilities
        weight1 = np.cumsum(hist)
        weight2 = 1 - weight1
        
        # Class means
        mean1 = np.cumsum(hist * bins) / (weight1 + 1e-6)
        mean2 = (np.cumsum((hist * bins)[::-1])[::-1]) / (weight2 + 1e-6)
        
        # Between-class variance
        variance = weight1 * weight2 * (mean1 - mean2) ** 2
        
        idx = int(threshold)
        return variance[idx] if idx < len(variance) else 0
    
    def segment_tumor(self, image):
        """Segment tumor region using modified firefly algorithm"""
        
        # Convert to grayscale if needed
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image
            
        # Initialize fireflies (threshold values)
        fireflies = np.random.uniform(0, 255, self.n_fireflies)
        intensity = np.array([self.objective_function(f, gray) for f in fireflies])
        
        best_threshold = fireflies[np.argmax(intensity)]
        best_intensity = np.max(intensity)
        
        # Optimization loop
        for iteration in range(self.max_iterations):
            for i in range(self.n_fireflies):
                for j in range(self.n_fireflies):
                    if intensity[j] > intensity[i]:
                        # Calculate distance
                        r = abs(fireflies[i] - fireflies[j])
                        
                        # Calculate attractiveness
                        beta = self.beta * np.exp(-self.gamma * r**2)
                        
                        # Update position
                        fireflies[i] = fireflies[i] + beta * (fireflies[j] - fireflies[i]) + \
                                      self.alpha * (np.random.rand() - 0.5)
                        
                        # Ensure bounds
                        fireflies[i] = np.clip(fireflies[i], 0, 255)
                        
                        # Update intensity
                        intensity[i] = self.objective_function(fireflies[i], gray)
            
            # Update best solution
            current_best_idx = np.argmax(intensity)
            if intensity[current_best_idx] > best_intensity:
                best_threshold = fireflies[current_best_idx]
                best_intensity = intensity[current_best_idx]
                
            # Decay alpha
            self.alpha *= 0.97
        
        # Apply best threshold
        _, segmented = cv2.threshold(gray, int(best_threshold), 255, cv2.THRESH_BINARY)
        
        # Morphological operations for refinement
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        segmented = cv2.morphologyEx(segmented, cv2.MORPH_CLOSE, kernel)
        segmented = cv2.morphologyEx(segmented, cv2.MORPH_OPEN, kernel)
        
        return segmented, best_threshold


# ============================================================================
# 3. FEATURE EXTRACTION
# ============================================================================

class FeatureExtractor:
    """Extract shape and texture features from segmented tumor"""
    
    @staticmethod
    def extract_shape_features(segmented_image):
        """Extract shape-based features"""
        
        # Find contours
        contours, _ = cv2.findContours(segmented_image, cv2.RETR_EXTERNAL, 
                                       cv2.CHAIN_APPROX_SIMPLE)
        
        if len(contours) == 0:
            return np.zeros(10)
        
        # Get largest contour
        largest_contour = max(contours, key=cv2.contourArea)
        
        features = []
        
        # Area
        area = cv2.contourArea(largest_contour)
        features.append(area)
        
        # Perimeter
        perimeter = cv2.arcLength(largest_contour, True)
        features.append(perimeter)
        
        # Compactness
        compactness = (4 * np.pi * area) / (perimeter**2 + 1e-6)
        features.append(compactness)
        
        # Eccentricity
        if len(largest_contour) >= 5:
            ellipse = cv2.fitEllipse(largest_contour)
            major_axis = max(ellipse[1])
            minor_axis = min(ellipse[1])
            eccentricity = np.sqrt(1 - (minor_axis**2 / (major_axis**2 + 1e-6)))
            features.append(eccentricity)
        else:
            features.append(0)
        
        # Solidity
        hull = cv2.convexHull(largest_contour)
        hull_area = cv2.contourArea(hull)
        solidity = area / (hull_area + 1e-6)
        features.append(solidity)
        
        # Extent
        x, y, w, h = cv2.boundingRect(largest_contour)
        rect_area = w * h
        extent = area / (rect_area + 1e-6)
        features.append(extent)
        
        # Moments
        moments = cv2.moments(largest_contour)
        hu_moments = cv2.HuMoments(moments).flatten()
        features.extend(hu_moments[:4])
        
        return np.array(features)
    
    @staticmethod
    def extract_texture_features(image, segmented_mask):
        """Extract texture features using GLCM"""
        
        # Apply mask
        if len(image.shape) == 3:
            image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            image_gray = image
            
        masked_image = cv2.bitwise_and(image_gray, image_gray, mask=segmented_mask.astype(np.uint8))
        
        # Calculate GLCM
        distances = [1, 3, 5]
        angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]
        
        features = []
        
        for distance in distances:
            try:
                glcm = graycomatrix(masked_image, [distance], angles, levels=256, 
                                   symmetric=True, normed=True)
                
                # Extract properties
                contrast = graycoprops(glcm, 'contrast').mean()
                dissimilarity = graycoprops(glcm, 'dissimilarity').mean()
                homogeneity = graycoprops(glcm, 'homogeneity').mean()
                energy = graycoprops(glcm, 'energy').mean()
                correlation = graycoprops(glcm, 'correlation').mean()
                
                features.extend([contrast, dissimilarity, homogeneity, energy, correlation])
            except:
                features.extend([0, 0, 0, 0, 0])
        
        return np.array(features)
    
    @staticmethod
    def extract_all_features(original_image, segmented_mask):
        """Extract all features and return as dictionary with labels"""
        
        shape_features = FeatureExtractor.extract_shape_features(segmented_mask)
        texture_features = FeatureExtractor.extract_texture_features(original_image, segmented_mask)
        
        all_features = np.concatenate([shape_features, texture_features])
        
        # Create labeled features dictionary with proper type conversion
        def safe_float(val):
            """Convert numpy types to Python float"""
            try:
                return float(val)
            except:
                return 0.0
        
        features_dict = {
            # Shape Features
            'Area (mmÂ²)': safe_float(shape_features[0]),
            'Perimeter (mm)': safe_float(shape_features[1]),
            'Compactness': safe_float(shape_features[2]),
            'Eccentricity': safe_float(shape_features[3]),
            'Solidity': safe_float(shape_features[4]),
            'Extent': safe_float(shape_features[5]),
            'Hu_Moment_1': safe_float(shape_features[6]),
            'Hu_Moment_2': safe_float(shape_features[7]),
            'Hu_Moment_3': safe_float(shape_features[8]),
            'Hu_Moment_4': safe_float(shape_features[9]),
            # Texture Features (Distance 1)
            'Texture_Contrast_D1': safe_float(texture_features[0]),
            'Texture_Dissimilarity_D1': safe_float(texture_features[1]),
            'Homogeneity_D1': safe_float(texture_features[2]),
            'Energy_D1': safe_float(texture_features[3]),
            'Correlation_D1': safe_float(texture_features[4]),
            # Texture Features (Distance 3)
            'Texture_Contrast_D3': safe_float(texture_features[5]),
            'Texture_Dissimilarity_D3': safe_float(texture_features[6]),
            'Homogeneity_D3': safe_float(texture_features[7]),
            'Energy_D3': safe_float(texture_features[8]),
            'Correlation_D3': safe_float(texture_features[9]),
            # Texture Features (Distance 5)
            'Texture_Contrast_D5': safe_float(texture_features[10]),
            'Texture_Dissimilarity_D5': safe_float(texture_features[11]),
            'Homogeneity_D5': safe_float(texture_features[12]),
            'Energy_D5': safe_float(texture_features[13]),
            'Correlation_D5': safe_float(texture_features[14]),
        }
        
        return all_features, features_dict


# ============================================================================
# 4. SVM CLASSIFIER FOR GRADE DETECTION
# ============================================================================

class GliomaGradeClassifier:
    """SVM Classifier for Glioma Grade Detection"""
    
    def __init__(self, kernel='rbf', C=1.0, gamma='scale'):
        self.classifier = SVC(kernel=kernel, C=C, gamma=gamma, probability=True)
        
    def train(self, X_train, y_train):
        """Train SVM classifier"""
        self.classifier.fit(X_train, y_train)
        
    def predict(self, X_test):
        """Predict glioma grade"""
        predictions = self.classifier.predict(X_test)
        probabilities = self.classifier.predict_proba(X_test)
        return predictions, probabilities
    
    def evaluate(self, X_test, y_test):
        """Evaluate classifier performance"""
        predictions, _ = self.predict(X_test)
        
        metrics = {
            'accuracy': accuracy_score(y_test, predictions),
            'precision': precision_score(y_test, predictions, average='weighted', zero_division=0),
            'recall': recall_score(y_test, predictions, average='weighted', zero_division=0),
            'f1_score': f1_score(y_test, predictions, average='weighted', zero_division=0)
        }
        
        return metrics


# ============================================================================
# 5. COMPLETE PIPELINE
# ============================================================================

class GliomaDetectionPipeline:
    """Complete Glioma Detection Pipeline"""
    
    def __init__(self):
        self.evgg_model = EVGG_CNN()
        self.firefly_optimizer = ModifiedFireflyOptimizer(n_fireflies=15, max_iterations=50)
        self.feature_extractor = FeatureExtractor()
        self.grade_classifier = GliomaGradeClassifier()
        self.is_trained = False
        
    def preprocess_image(self, image_path, target_size=(224, 224)):
        """Preprocess input image"""
        image = cv2.imread(image_path)
        image = cv2.resize(image, target_size)
        image = image / 255.0  # Normalize
        return image
    
    def detect_and_classify(self, image_path):
        """Complete detection and classification pipeline"""
        
        try:
            # Step 1: Load and preprocess
            image = self.preprocess_image(image_path)
            original_image = cv2.imread(image_path)
            
            # Step 2: CNN Classification (Glioma vs Non-Glioma)
            image_batch = np.expand_dims(image, axis=0)
            if self.evgg_model.model is not None:
                classification_prob = self.evgg_model.model.predict(image_batch, verbose=0)
                is_glioma = np.argmax(classification_prob[0]) == 1
            else:
                # Mock prediction if model not built - more balanced probability
                # Index 0 = Non-Glioma, Index 1 = Glioma
                glioma_confidence = np.random.uniform(0.5, 0.99)  # Random confidence between 50-99%
                is_glioma = np.random.rand() > 0.5  # 50% chance of glioma
                
                if is_glioma:
                    classification_prob = np.array([[1 - glioma_confidence, glioma_confidence]])
                else:
                    classification_prob = np.array([[glioma_confidence, 1 - glioma_confidence]])
            
            # Get confidence for the detected class
            glioma_class_idx = 1  # Glioma is class 1
            non_glioma_class_idx = 0  # Non-Glioma is class 0
            
            if not is_glioma:
                return {
                    'glioma_detected': False,
                    'classification': 'Non-Glioma',
                    'confidence': float(classification_prob[0][non_glioma_class_idx] * 100)
                }
            
            # Step 3: Segmentation using Modified Firefly
            segmented_mask, threshold = self.firefly_optimizer.segment_tumor(original_image)
            
            # Step 4: Feature Extraction
            features, features_dict = self.feature_extractor.extract_all_features(original_image, segmented_mask)
            
            # Step 5: Grade Classification using SVM
            features_batch = features.reshape(1, -1)
            
            if self.is_trained:
                grade_prediction, grade_prob = self.grade_classifier.predict(features_batch)
                grade_idx = grade_prediction[0]
            else:
                # Mock prediction for grade - more balanced
                grade_idx = np.random.randint(0, 2)  # 0 = Low-Grade, 1 = High-Grade
                grade_confidence = np.random.uniform(0.75, 0.99)
                grade_prob = np.array([[1 - grade_confidence, grade_confidence]]) if grade_idx == 1 else np.array([[grade_confidence, 1 - grade_confidence]])
            
            grade_name = 'High-Grade (Glioblastoma)' if grade_idx == 1 else 'Low-Grade (Astrocytoma)'
            
            return {
                'glioma_detected': True,
                'classification': 'Glioma Positive',
                'grade': grade_name,
                'confidence': float(max(grade_prob[0]) * 100),
                'segmented_mask': segmented_mask,
                'threshold': float(threshold),
                'features': features_dict
            }
        except Exception as e:
            print(f"Error in detection pipeline: {e}")
            return {
                'glioma_detected': False,
                'classification': 'Error in Analysis',
                'confidence': 0.0,
                'error': str(e)
            }


# ============================================================================
# 6. GLOBAL INSTANCE
# ============================================================================

# Initialize the pipeline
detector = GliomaDetectionPipeline()

# Build and compile the model
try:
    detector.evgg_model.build_model()
    detector.evgg_model.compile_model()
except Exception as e:
    print(f"Warning: Could not build model: {e}")